{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import torch\n",
    "import numpy\n",
    "import pandas\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    " \n",
    "from torch import nn\n",
    "\n",
    "#JULIA\n",
    "\n",
    "# # Set display width, load packages, import symbols\n",
    "# ENV[\"COLUMNS\"]=72\n",
    "# using Pkg\n",
    "# # Check installed packages and install uninstalled ones\n",
    "# isinstalled(pkg::String) = any(x -> x.name == pkg && x.is_direct_dep, values(Pkg.dependencies()))\n",
    "# pk = [\"Knet\",\"Statistics\",\"IterTools\", \"MLDatasets\", \"Plots\",\"CUDA\"]\n",
    "# using Pkg;\n",
    "# for p in pk\n",
    "#     if isinstalled(p)==false\n",
    "#         println(\"Installing \", p)\n",
    "#         Pkg.add(p)\n",
    "#     else\n",
    "#         println(\"Found \", p)\n",
    "#     end\n",
    "# end\n",
    "# # for p in pk; isinstalled(p) || Pkg.add(p); end\n",
    "\n",
    "\n",
    "# using Base.Iterators: flatten\n",
    "# using IterTools: ncycle, takenth\n",
    "# using Statistics: mean\n",
    "# using MLDatasets: MNIST\n",
    "# import CUDA # functional\n",
    "# import Knet # load, save\n",
    "# using Knet: conv4, pool, mat, KnetArray, nll, accuracy, progress, sgd, param, param0, training, dropout, relu, minibatch, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "600\n",
      "100\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Some libraries for a data to load from\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([ # Transoforms the data to Tensor\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load MNIST Dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform) # Train = True means Training Set\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform) # Train = False means Test Set\n",
    "print(len(mnist_trainset)) # Size of mnist trainset is 60000\n",
    "print(len(mnist_testset)) # Size of mnist testset is 10000\n",
    "\n",
    "# Assigning Some Values Beforehand\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "lr_rate = 0.1\n",
    "\n",
    "# Construct minibatches from train_dataloaders and test_dataloader = [ (x1,y1), (x2,y2), ... ] \n",
    "# (xi,yi) are minibatch pairs of size 100 samples each\n",
    "# Each sample in a minibatch pair (xi,yi) is of size 784 and 1 for x and y\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "train_dataloaders = DataLoader(mnist_trainset, # MNIST trainset\n",
    "                                batch_size=batch_size, # 100 batches\n",
    "                                shuffle=True, # Shuffle the batches\n",
    "                                drop_last=False # Dont drop the last batch\n",
    "                     )\n",
    "\n",
    "print(len(train_dataloaders)) # Length will be 600 because there are 600 batches\n",
    "\n",
    "test_dataloader  = DataLoader(mnist_testset, # MNIST testset\n",
    "                              batch_size=batch_size, # 100 batches\n",
    "                              shuffle=False)\n",
    "\n",
    "print(len(test_dataloader)) # Length will be 100 because there are 100 batches\n",
    "\n",
    "dataiter = iter(train_dataloaders) # iterating the trainset batches\n",
    "(train_features, train_labels) = next(dataiter) # Take the first minibatch\n",
    "print(train_features.shape) # features of one minibatch will have the 4D size of [100, 1, 28, 28]\n",
    "\n",
    "print(train_labels.shape) # # labels of one minibatch will have the size of [100]\n",
    "\n",
    "#JULIA\n",
    "\n",
    "# # Load MNIST data\n",
    "# xtrn,ytrn = MNIST.traindata(Float32); # Training Set\n",
    "# ytrn[ytrn.==0] .= 10 # Change label 0 to 10\n",
    "# xtst,ytst = MNIST.testdata(Float32);  # Test Set\n",
    "# ytst[ytst.==0] .= 10 # Change label 0 to 10\n",
    "# println(\"Summary of xtrn: \",summary(xtrn))\n",
    "# println(\"Summary of ytrn: \",summary(ytrn))\n",
    "\n",
    "# # Construct minibatches dtrn and dtst = [ (x1,y1), (x2,y2), ... ] \n",
    "# # (xi,yi) are minibatch pairs of size 100 samples each\n",
    "# # Each sample in a minibatch pair (xi,yi) is of size 28x28 and 1 for x and y\n",
    "# dtrn = minibatch(xtrn, ytrn, 100; xsize = (28,28,1,:)) # EE58A: Note that we must have used KnetArray and 4D tensor this time\n",
    "# dtst = minibatch(xtst, ytst, 100; xsize = (28,28,1,:)) # EE58A: Note that we must have used KnetArray and 4D tensor this time\n",
    "# println(\"# of training batches in dtrn: \",length(dtrn),\" ; # of testing batches in dtst: \",length(dtst))\n",
    "\n",
    "# (x,y) = first(dtrn) # Take the first minibatch\n",
    "# println.(summary.((x,y))); #<<<<<<<<<<<<<<<<<<<<<<< EE58A: There could be an issue with not using KnetArray\n",
    "# minibatch_data_size = size.((x,y))[1] # Takes the size of x\n",
    "# println(\"Single minibatch data size:\", minibatch_data_size)\n",
    "# minibatch_label_size = size.((x,y))[2] # Takes the size of y\n",
    "# println(\"Single minibatch label size:\", minibatch_label_size)\n",
    "\n",
    "\n",
    "# max_label = findmax(y)[1]\n",
    "# println(\"Max Label:\",findmax(y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch Linear Model like a Dense Model in Julia\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features,pdrop=0, bias=True): # Defining necessary parameters in init function\n",
    "        super().__init__()\n",
    "        self.in_features = in_features # Defining input features\n",
    "        self.out_features = out_features # Defining output features\n",
    "        self.bias = bias # Defining bias\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(out_features, in_features)) # Defining weight matrix\n",
    "        self.dropout = nn.Dropout(pdrop) # Defining Dropout\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_features)) # Take the bias if it's a parameter of output features\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(self.bias, -bound, bound)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x, y = input.shape\n",
    "        if y != self.in_features: # Checking if the input column numbers are matched with the expected number\n",
    "            print(f'Wrong Input Features. Please use tensor with {self.in_features} Input Features')\n",
    "            return 0\n",
    "        input = self.dropout(input) # Dropout\n",
    "        output = input.matmul(self.weight.t()) # Matrix multiplication between Weights and input\n",
    "        if self.bias is not None:\n",
    "            output += self.bias # Adding biases if there is any\n",
    "        ret = output\n",
    "        return ret\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "\n",
    "\n",
    "# JULIA\n",
    "\n",
    "# # Dense (Fully Connected) layer with\n",
    "# #       Dropout\n",
    "# struct Dense; w; b; f; p; end\n",
    "# (d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b) # mat reshapes 4-D tensor to 2-D matrix with one dim being \n",
    "# #                                                        the cases/samples\n",
    "# Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layer with\n",
    "      Dropout\n",
    "      Default Pooling: Max pooling with 2x2 kernel size (Note that this will change single sample data size\n",
    "\n",
    "-Convolves with w and adds a bias b\n",
    "  \n",
    "\n",
    "Dense (Fully Connected) layer with Dropout (Linear layers)\n",
    "\n",
    "-mat reshapes 4-D tensor to 2-D matrix with one dim being the cases/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN class\n",
    "class ConvNeuralNet(nn.Module):\n",
    "\t#  Determine what layers and their order in CNN object \n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5) # 5x5 conv. kernel, single input channel, 20 output channels\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)                  # Due to no-padding and 2x2 pooling single output is 12x12 \n",
    "                                                                                    # (28-(2+2))/2 = 12\n",
    "\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5)# 5x5 conv. kernel, 20 input channels, 50 output channels\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)                  # Due to no-padding and 2x2 pooling single output is 4x4 \n",
    "                                                                                    # (12-(2+2)/2) = 4\n",
    "\n",
    "        self.fc1 = Linear(800, 500,pdrop=0.3) # 4x4x50=800 all flattened. Output is 500 dimensional\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = Linear(500, 10,pdrop=0.3)  # 500-to-10 dimensions (10 labels)\n",
    "\n",
    "    def forward(self,X):\n",
    "        X=self.max_pool1(self.conv_layer1(X)) # Convolutional Layer 1 and pooling\n",
    "        X=self.max_pool2(self.conv_layer2(X)) # Convolutional Layer 2 and pooling\n",
    "        \n",
    "        X = X.reshape(X.size(0), -1) # Flattening X for linear layers\n",
    "\n",
    "        X = self.relu1(self.fc1(X)) #Linear layer 1\n",
    "        X = self.fc2(X) #Linear layer 2\n",
    "        return X\n",
    "\n",
    "    def compute_l1_loss(self, w): # Computing L1 norm penalty\n",
    "        return torch.abs(w).sum()\n",
    "    \n",
    "    def compute_l2_loss(self, w): # Computing L2 norm penalty\n",
    "        return torch.pow(w,2).sum()\n",
    "\n",
    "#JULIA\n",
    "\n",
    "\n",
    "# # Convolution layer with\n",
    "# #       Dropout\n",
    "# #       Default Pooling: Max pooling with 2x2 kernel size (Note that this will change single sample data size\n",
    "# #                                                          but this is not a concern while defining convolution layers)\n",
    "# struct Conv; w; b; f; p; end\n",
    "# (c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b)) # Convolves with w and adds a bias b\n",
    "# Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)\n",
    "\n",
    "\n",
    "# struct Chain\n",
    "#     layers; λ1; λ2\n",
    "#     Chain(layers...; λ1=0, λ2=0) = new(layers, λ1, λ2)\n",
    "# end\n",
    "# # Below are function definitions that use a stack of layers (ie a chain)\n",
    "# # Chain input : A minibatch of x\n",
    "# # Chain output: Whatever is computed by the chain \n",
    "# (c::Chain)(x) = (for l in c.layers; x = l(x); end; x)\n",
    "# # Chain input : A minibatch of x and y (labels)\n",
    "# # Chain output: NLL loss computed with chain output and the true labels, y's \n",
    "# function (c::Chain)(x,y)\n",
    "#     loss = Knet.nll(c(x),y)\n",
    "#     if training() # Only apply regularization during training, only to weights, not biases.\n",
    "#         c.λ1 != 0 && (loss += c.λ1 * sum(sum(abs, l.w) for l in c.layers)) #L1 norm penalty applied if λ1!=0\n",
    "#         c.λ2 != 0 && (loss += c.λ2 * sum(sum(abs2,l.w) for l in c.layers)) #L2 norm penalty applied if λ2!=0\n",
    "#     end\n",
    "#     return loss\n",
    "# end\n",
    "# # Chain input : A set of minibatches of x and y (labels)\n",
    "# # Chain output: Mean NLL loss computed with chain output and the true labels, y's, over all minibatches in the set\n",
    "# (c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)\n",
    "\n",
    "\n",
    "# lenet =   Chain(Conv(5,5,1,20),            # 5x5 conv. kernel, single input channel, 20 output channels\n",
    "#                                            # Due to no-padding and 2x2 pooling single output is 12x12 \n",
    "#                                            # (28-(2+2))/2 = 12\n",
    "#                 Conv(5,5,20,50),           # 5x5 conv. kernel, 20 input channels, 50 output channels\n",
    "#                                            # Due to no-padding and 2x2 pooling single output is 4x4 \n",
    "#                                            # (12-(2+2)/2) = 4\n",
    "#                 Dense(800,500,pdrop=0.3),  # 4x4x50=800 all flattened by mat(). Output is 500 dimensional\n",
    "#                 Dense(500,10,identity,pdrop=0.3)) # 500-to-10 dimensions (10 labels)\n",
    "# summary.(l.w for l in lenet.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating the minibatches and saving the results for trainset and testset\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn,loss_array, optimizer, l1_lambda=0, l2_lambda=0):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader): # Batch number , X for each batch, y for each batch\n",
    "        # Compute prediction and loss\n",
    "        # X.resize_(100,784) # Resizing X from 4D to 2D\n",
    "        pred = model(X) # Getting predictions\n",
    "        loss = loss_fn(pred, y) # Calculating loss for each minibatch\n",
    "\n",
    "        # Only apply regularization during training, only to weights, not biases.\n",
    "\n",
    "        # Compute L1 loss component\n",
    "        if l1_lambda !=0: #L1 norm penalty applied if λ1!=0\n",
    "            l1_parameters = []\n",
    "            for parameter in model.parameters():\n",
    "                l1_parameters.append(parameter.view(-1))\n",
    "            l1 = l1_lambda * model.compute_l1_loss(torch.cat(l1_parameters))\n",
    "        \n",
    "            # Add L1 loss component\n",
    "            loss += l1\n",
    "        \n",
    "        # Compute L2 loss component\n",
    "        if l2_lambda !=0: #L2 norm penalty applied if λ1!=0\n",
    "            l2_parameters = []\n",
    "            for parameter in model.parameters():\n",
    "                l2_parameters.append(parameter.view(-1))\n",
    "            l2 = l2_lambda * model.compute_l2_loss(torch.cat(l2_parameters))\n",
    "        \n",
    "            # Add L2 loss component\n",
    "            loss += l2\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0: # Printing losses at each 100 batches\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        if batch % 600 == 0: # saving loss of each epoch\n",
    "            loss_array.append(loss)\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, loss_array):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader: # X for each batch, y for each batch\n",
    "            # X.resize_(100,784) # Resizing X from 4D to 2D\n",
    "            pred = model(X) # Getting predictions\n",
    "            test_loss += loss_fn(pred, y).item() # Calculating total loss\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item() # Calculating accuracy\n",
    "\n",
    "    test_loss /= num_batches # Calculating average loss\n",
    "    loss_array.append(test_loss) # saving loss of each epoch\n",
    "    correct /= size  # Calculating average accuracy\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.269990  [    0/60000]\n",
      "loss: 1.410116  [10000/60000]\n",
      "loss: 1.202792  [20000/60000]\n",
      "loss: 1.169983  [30000/60000]\n",
      "loss: 0.880455  [40000/60000]\n",
      "loss: 0.812217  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.131852 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.747317  [    0/60000]\n",
      "loss: 0.760691  [10000/60000]\n",
      "loss: 0.642808  [20000/60000]\n",
      "loss: 0.595675  [30000/60000]\n",
      "loss: 0.634149  [40000/60000]\n",
      "loss: 0.681371  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.095605 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.540697  [    0/60000]\n",
      "loss: 0.470099  [10000/60000]\n",
      "loss: 0.420877  [20000/60000]\n",
      "loss: 0.394164  [30000/60000]\n",
      "loss: 0.383937  [40000/60000]\n",
      "loss: 0.463403  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.116374 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.354576  [    0/60000]\n",
      "loss: 0.407172  [10000/60000]\n",
      "loss: 0.403662  [20000/60000]\n",
      "loss: 0.332989  [30000/60000]\n",
      "loss: 0.326529  [40000/60000]\n",
      "loss: 0.427423  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.092810 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.369904  [    0/60000]\n",
      "loss: 0.283918  [10000/60000]\n",
      "loss: 0.324806  [20000/60000]\n",
      "loss: 0.279817  [30000/60000]\n",
      "loss: 0.282325  [40000/60000]\n",
      "loss: 0.290885  [50000/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.078885 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = ConvNeuralNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
    "train_loss_array, test_loss_array = [],[]\n",
    "# torch.save(model.state_dict(), PATH) # To save gpu memory\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs): # Iterating 5 epoches\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloaders, model, loss_fn,train_loss_array, optimizer,l1_lambda=0.0001,l2_lambda=0.001)\n",
    "    test_loop(test_dataloader, model, loss_fn,test_loss_array)\n",
    "print(\"Done!\")\n",
    "\n",
    "#JULIA\n",
    "\n",
    "# function trainresults(file,model,epochs,dtrn,dtst,savemodel)\n",
    "#     if (print(\"Train from scratch? \"); readline()[1]=='y')\n",
    "#         training = sgd(model, ncycle(dtrn,epochs))\n",
    "#         snapshot() = (model(dtrn),model(dtst),1-accuracy(model;data=dtrn),1-accuracy(model;data=dtst))\n",
    "#         snapshots = (snapshot() for x in takenth(progress(training),length(dtrn)))\n",
    "#         results = reshape(collect(Float32,flatten(snapshots)),(4,:))\n",
    "#         Knet.save(file,\"model\",(savemodel ? model : nothing),\"results\",results)\n",
    "#         GC.gc(true) # To save gpu memory\n",
    "#     else\n",
    "#         # isfile(file) || download(\"http://people.csail.mit.edu/deniz/models/tutorial/$file\",file)\n",
    "#         model,results = Knet.load143(file,\"model\",\"results\")\n",
    "#     end \n",
    "#     return results\n",
    "# end\n",
    "\n",
    "# lenet_res = trainresults(\"cnn.jld2\",lenet,10,dtrn,dtst,true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'CNN Loss')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization\n",
    "\n",
    "test_lost_array = Tensor(test_loss_array)\n",
    "train_loss_array = Tensor(train_loss_array)\n",
    "\n",
    "plt.plot(range(1,epochs),train_loss_array[1:], label='Trainloss', color = 'red')\n",
    "plt.plot(range(1,epochs),test_loss_array[1:], label='Testloss', color = 'blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('CNN Loss')\n",
    "\n",
    "#JULIA\n",
    "\n",
    "# using Plots; default(fmt = :png)\n",
    "# println(\"The snapshot logs - LeNet - has size = \",size(lenet_res))\n",
    "# println(\"Final accuracy on test set = \",accuracy(lenet;data=dtst))\n",
    "\n",
    "# trnloss,tstloss = Array{Float32}(lenet_res[1,:]), Array{Float32}(lenet_res[2,:]) \n",
    "# plot([trnloss,tstloss],labels=[\"trnloss\" \"tstloss\"],xlabel=\"Epochs\",ylabel=\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare CNN to MLP and note the following\n",
    "* There is no difference between the class of functions representable with an MLP vs CNN.\n",
    "* CNNs converge faster and have better generalization capability\n",
    "* CNNs are specifically good for data represented on graph structures, such as images (where the grid is the graph)\n",
    "* Better find a GPU for CNNs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b4a3e8622309bcc6db3d5cc6eb73d60ab98d9ec23bad6a26b709981ccb403a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
